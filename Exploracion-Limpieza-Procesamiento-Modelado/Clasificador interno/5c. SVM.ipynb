{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1638671890722,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "sX_k3xQPTtp8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report, recall_score, f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1482,
     "status": "ok",
     "timestamp": 1638670391243,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "4Cr1_SwFTtqC",
    "outputId": "99c73fde-9aba-4cc3-d640-14d2d7223a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time datos = pd.read_csv('data_equilibrada.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1638670391244,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "cppPNsEObVqe",
    "outputId": "3e6b0ffb-694e-4cd9-b942-294272e48ea0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1479, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2477,
     "status": "ok",
     "timestamp": 1638670393719,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "xBF1T_NtTtqD",
    "outputId": "70bed5a9-46b4-4d4b-8413-4db0beb5cb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "%time datos.tokens=datos.tokens.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1638670395920,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "XzPMzYueTtqE"
   },
   "outputs": [],
   "source": [
    "bow = pd.read_csv('bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1638670399386,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "YSWgG2xdTtqE",
    "outputId": "0a2d49b9-e7a6-49ab-8ab0-11b6a6cd91b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 66.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time tfidf=pd.DataFrame(TfidfVectorizer(vocabulary=bow.token.values).fit_transform(datos['tokens'].str.join(\" \")).toarray(), columns=bow.token.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1638670400449,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "iHNhVMcnTtqE",
    "outputId": "81dfeaf1-2218-4a01-a9d3-4c7092c91126"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop</th>\n",
       "      <th>unsubscrib</th>\n",
       "      <th>verifi</th>\n",
       "      <th>inform</th>\n",
       "      <th>request</th>\n",
       "      <th>thank</th>\n",
       "      <th>address</th>\n",
       "      <th>lafargeholcim</th>\n",
       "      <th>benefit</th>\n",
       "      <th>com</th>\n",
       "      <th>...</th>\n",
       "      <th>chart</th>\n",
       "      <th>brotherhood</th>\n",
       "      <th>tanker</th>\n",
       "      <th>driver</th>\n",
       "      <th>vous</th>\n",
       "      <th>webmanag</th>\n",
       "      <th>theworknumb</th>\n",
       "      <th>ppay</th>\n",
       "      <th>tci</th>\n",
       "      <th>usf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070336</td>\n",
       "      <td>0.071192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099912</td>\n",
       "      <td>0.119191</td>\n",
       "      <td>0.114623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>0.084983</td>\n",
       "      <td>0.086018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.107704</td>\n",
       "      <td>0.109015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows × 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stop  unsubscrib    verifi    inform   request     thank   address  \\\n",
       "0     0.000000    0.000000  0.093465  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.062238   \n",
       "2     0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000    0.000000  0.000000  0.126601  0.000000  0.093610  0.000000   \n",
       "4     0.070336    0.071192  0.000000  0.000000  0.000000  0.084040  0.000000   \n",
       "...        ...         ...       ...       ...       ...       ...       ...   \n",
       "1474  0.084983    0.086018  0.000000  0.000000  0.000000  0.101541  0.000000   \n",
       "1475  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1476  0.019315    0.019551  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1477  0.107704    0.109015  0.000000  0.000000  0.000000  0.128688  0.000000   \n",
       "1478  0.000000    0.000000  0.300265  0.000000  0.371938  0.000000  0.128300   \n",
       "\n",
       "      lafargeholcim   benefit       com  ...  chart  brotherhood  tanker  \\\n",
       "0          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "1          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "2          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "3          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "4          0.099912  0.119191  0.114623  ...    0.0          0.0     0.0   \n",
       "...             ...       ...       ...  ...    ...          ...     ...   \n",
       "1474       0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "1475       0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "1476       0.082313  0.000000  0.031478  ...    0.0          0.0     0.0   \n",
       "1477       0.000000  0.000000  0.175520  ...    0.0          0.0     0.0   \n",
       "1478       0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "\n",
       "      driver      vous  webmanag  theworknumb  ppay  tci  usf  \n",
       "0        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "2        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "3        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "4        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "...      ...       ...       ...          ...   ...  ...  ...  \n",
       "1474     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1475     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1476     0.0  0.447812       0.0          0.0   0.0  0.0  0.0  \n",
       "1477     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1478     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "\n",
       "[1479 rows x 708 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1638670405821,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "8hikogBcTtqF"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf.values, datos.etiquetas.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6780,
     "status": "ok",
     "timestamp": 1638672165544,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "BDQCftC62wyI",
    "outputId": "fb6c1a30-8eea-453e-8272-bcea16537374",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.5\n",
      "Train:\n",
      "[[132   3   1   3   3   2   5]\n",
      " [  2 227   0   1   1   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  1   1   0 171   0   0   0]\n",
      " [  6   0   0   1 152   0   1]\n",
      " [  0   0   0   0   0 144   3]\n",
      " [  8   0   0   1   0  12 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       149\n",
      "           1       0.98      0.98      0.98       231\n",
      "           2       0.99      1.00      1.00       181\n",
      "           3       0.97      0.99      0.98       173\n",
      "           4       0.97      0.95      0.96       160\n",
      "           5       0.91      0.98      0.94       147\n",
      "           6       0.93      0.85      0.89       142\n",
      "\n",
      "    accuracy                           0.95      1183\n",
      "   macro avg       0.95      0.95      0.95      1183\n",
      "weighted avg       0.95      0.95      0.95      1183\n",
      "\n",
      "Test:\n",
      "[[23  4  2  2  3  1  2]\n",
      " [ 1 50  1  1  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  0 34  0  3]\n",
      " [ 0  0  0  0  0 50  1]\n",
      " [ 3  1  0  1  2  5 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.70        37\n",
      "           1       0.91      0.93      0.92        54\n",
      "           2       0.93      1.00      0.96        41\n",
      "           3       0.90      1.00      0.95        36\n",
      "           4       0.87      0.87      0.87        39\n",
      "           5       0.89      0.98      0.93        51\n",
      "           6       0.79      0.68      0.73        38\n",
      "\n",
      "    accuracy                           0.88       296\n",
      "   macro avg       0.87      0.87      0.87       296\n",
      "weighted avg       0.87      0.88      0.87       296\n",
      "\n",
      "-----------\n",
      "C: 1.0\n",
      "Train:\n",
      "[[140   0   0   1   3   2   3]\n",
      " [  2 228   0   0   1   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 145   2]\n",
      " [  7   0   0   0   0  10 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       149\n",
      "           1       1.00      0.99      0.99       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       0.99      1.00      1.00       173\n",
      "           4       0.97      0.96      0.97       160\n",
      "           5       0.92      0.99      0.95       147\n",
      "           6       0.95      0.88      0.92       142\n",
      "\n",
      "    accuracy                           0.97      1183\n",
      "   macro avg       0.96      0.96      0.96      1183\n",
      "weighted avg       0.97      0.97      0.97      1183\n",
      "\n",
      "Test:\n",
      "[[24  3  1  2  4  1  2]\n",
      " [ 1 50  1  1  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  0 34  0  3]\n",
      " [ 0  0  0  0  0 50  1]\n",
      " [ 2  1  0  0  2  5 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73        37\n",
      "           1       0.93      0.93      0.93        54\n",
      "           2       0.95      1.00      0.98        41\n",
      "           3       0.92      1.00      0.96        36\n",
      "           4       0.85      0.87      0.86        39\n",
      "           5       0.89      0.98      0.93        51\n",
      "           6       0.80      0.74      0.77        38\n",
      "\n",
      "    accuracy                           0.89       296\n",
      "   macro avg       0.88      0.88      0.88       296\n",
      "weighted avg       0.89      0.89      0.88       296\n",
      "\n",
      "-----------\n",
      "C: 1.5\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 145   2]\n",
      " [  7   0   0   0   0   8 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.95      0.99      0.97       147\n",
      "           6       0.95      0.89      0.92       142\n",
      "\n",
      "    accuracy                           0.97      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.97      0.97      0.97      1183\n",
      "\n",
      "Test:\n",
      "[[24  2  1  2  4  2  2]\n",
      " [ 1 50  1  1  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  0 34  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  4 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73        37\n",
      "           1       0.93      0.93      0.93        54\n",
      "           2       0.95      1.00      0.98        41\n",
      "           3       0.92      1.00      0.96        36\n",
      "           4       0.85      0.87      0.86        39\n",
      "           5       0.89      0.96      0.92        51\n",
      "           6       0.81      0.76      0.78        38\n",
      "\n",
      "    accuracy                           0.89       296\n",
      "   macro avg       0.88      0.88      0.88       296\n",
      "weighted avg       0.89      0.89      0.89       296\n",
      "\n",
      "-----------\n",
      "C: 2.0\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 145   2]\n",
      " [  7   0   0   0   0   7 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.95      0.99      0.97       147\n",
      "           6       0.96      0.90      0.93       142\n",
      "\n",
      "    accuracy                           0.97      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.98      0.97      0.97      1183\n",
      "\n",
      "Test:\n",
      "[[24  2  1  2  4  2  2]\n",
      " [ 1 50  1  1  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  0 34  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  4 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73        37\n",
      "           1       0.93      0.93      0.93        54\n",
      "           2       0.95      1.00      0.98        41\n",
      "           3       0.92      1.00      0.96        36\n",
      "           4       0.85      0.87      0.86        39\n",
      "           5       0.89      0.96      0.92        51\n",
      "           6       0.81      0.76      0.78        38\n",
      "\n",
      "    accuracy                           0.89       296\n",
      "   macro avg       0.88      0.88      0.88       296\n",
      "weighted avg       0.89      0.89      0.89       296\n",
      "\n",
      "-----------\n",
      "C: 2.5\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  6   0   0   0   0   7 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.95      1.00      0.98       147\n",
      "           6       0.97      0.91      0.94       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.98      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[24  2  1  2  4  2  2]\n",
      " [ 1 50  1  1  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  0 34  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  4 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73        37\n",
      "           1       0.93      0.93      0.93        54\n",
      "           2       0.95      1.00      0.98        41\n",
      "           3       0.92      1.00      0.96        36\n",
      "           4       0.85      0.87      0.86        39\n",
      "           5       0.89      0.96      0.92        51\n",
      "           6       0.81      0.76      0.78        38\n",
      "\n",
      "    accuracy                           0.89       296\n",
      "   macro avg       0.88      0.88      0.88       296\n",
      "weighted avg       0.89      0.89      0.89       296\n",
      "\n",
      "-----------\n",
      "C: 3.0\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  6   0   0   0   0   7 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.95      1.00      0.98       147\n",
      "           6       0.97      0.91      0.94       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.98      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[24  2  1  1  4  3  2]\n",
      " [ 1 50  1  1  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  1 33  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  4 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73        37\n",
      "           1       0.93      0.93      0.93        54\n",
      "           2       0.95      1.00      0.98        41\n",
      "           3       0.92      1.00      0.96        36\n",
      "           4       0.85      0.85      0.85        39\n",
      "           5       0.88      0.96      0.92        51\n",
      "           6       0.81      0.76      0.78        38\n",
      "\n",
      "    accuracy                           0.89       296\n",
      "   macro avg       0.88      0.88      0.88       296\n",
      "weighted avg       0.88      0.89      0.88       296\n",
      "\n",
      "-----------\n",
      "C: 3.5\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  7   0   0   0   0   6 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.96      1.00      0.98       147\n",
      "           6       0.97      0.91      0.94       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.98      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[24  2  0  1  4  4  2]\n",
      " [ 1 49  1  2  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  1 33  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  3 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73        37\n",
      "           1       0.92      0.91      0.92        54\n",
      "           2       0.98      1.00      0.99        41\n",
      "           3       0.90      1.00      0.95        36\n",
      "           4       0.85      0.85      0.85        39\n",
      "           5       0.88      0.96      0.92        51\n",
      "           6       0.81      0.79      0.80        38\n",
      "\n",
      "    accuracy                           0.89       296\n",
      "   macro avg       0.88      0.88      0.88       296\n",
      "weighted avg       0.88      0.89      0.88       296\n",
      "\n",
      "-----------\n",
      "C: 4.0\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  7   0   0   0   0   6 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.96      1.00      0.98       147\n",
      "           6       0.97      0.91      0.94       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.98      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[23  2  0  1  4  4  3]\n",
      " [ 1 49  1  2  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  1 33  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  3 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.62      0.71        37\n",
      "           1       0.92      0.91      0.92        54\n",
      "           2       0.98      1.00      0.99        41\n",
      "           3       0.90      1.00      0.95        36\n",
      "           4       0.85      0.85      0.85        39\n",
      "           5       0.88      0.96      0.92        51\n",
      "           6       0.79      0.79      0.79        38\n",
      "\n",
      "    accuracy                           0.88       296\n",
      "   macro avg       0.88      0.88      0.87       296\n",
      "weighted avg       0.88      0.88      0.88       296\n",
      "\n",
      "-----------\n",
      "C: 4.5\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  7   0   0   0   0   6 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.96      1.00      0.98       147\n",
      "           6       0.97      0.91      0.94       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.98      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[23  2  0  1  4  4  3]\n",
      " [ 1 49  1  2  0  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  1 33  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  3 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.62      0.71        37\n",
      "           1       0.92      0.91      0.92        54\n",
      "           2       0.98      1.00      0.99        41\n",
      "           3       0.90      1.00      0.95        36\n",
      "           4       0.85      0.85      0.85        39\n",
      "           5       0.88      0.96      0.92        51\n",
      "           6       0.79      0.79      0.79        38\n",
      "\n",
      "    accuracy                           0.88       296\n",
      "   macro avg       0.88      0.88      0.87       296\n",
      "weighted avg       0.88      0.88      0.88       296\n",
      "\n",
      "-----------\n",
      "C: 5.0\n",
      "Train:\n",
      "[[144   0   0   0   2   0   3]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  6   0   0   0 153   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  7   0   0   0   0   6 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       0.99      0.96      0.97       160\n",
      "           5       0.96      1.00      0.98       147\n",
      "           6       0.97      0.91      0.94       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.97      0.97      0.97      1183\n",
      "weighted avg       0.98      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[23  2  0  1  4  4  3]\n",
      " [ 1 48  1  2  1  0  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0]\n",
      " [ 2  0  0  1 33  0  3]\n",
      " [ 0  1  0  0  0 49  1]\n",
      " [ 2  1  0  0  2  3 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.62      0.71        37\n",
      "           1       0.92      0.89      0.91        54\n",
      "           2       0.98      1.00      0.99        41\n",
      "           3       0.90      1.00      0.95        36\n",
      "           4       0.82      0.85      0.84        39\n",
      "           5       0.88      0.96      0.92        51\n",
      "           6       0.79      0.79      0.79        38\n",
      "\n",
      "    accuracy                           0.88       296\n",
      "   macro avg       0.87      0.87      0.87       296\n",
      "weighted avg       0.88      0.88      0.87       296\n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "cms_train=[]\n",
    "cms_test=[]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "reporte_train = []\n",
    "reporte_test = []\n",
    "Cs=np.arange(0.5,5.5,0.5)\n",
    "for C in Cs:\n",
    "    print(\"C:\",C)\n",
    "    svm = LinearSVC(C=C)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    predicciones_train=svm.predict(X_train)\n",
    "    predicciones_test=svm.predict(X_test)\n",
    "\n",
    "    cms_train.append(confusion_matrix(y_train,predicciones_train))\n",
    "    cms_test.append(confusion_matrix(y_test,predicciones_test))\n",
    "    accuracy_train.append(accuracy_score(y_train,predicciones_train))\n",
    "    accuracy_test.append(accuracy_score(y_test,predicciones_test))\n",
    "    f1_train.append(f1_score(y_train,predicciones_train,average='weighted'))\n",
    "    f1_test.append(f1_score(y_test,predicciones_test,average='weighted'))\n",
    "    recall_train.append(recall_score(y_train,predicciones_train,average='weighted'))\n",
    "    recall_test.append(recall_score(y_test,predicciones_test,average='weighted'))\n",
    "    reporte_train.append(precision_recall_fscore_support(y_train,predicciones_train))\n",
    "    reporte_test.append(precision_recall_fscore_support(y_test,predicciones_test))\n",
    "\n",
    "    print(\"Train:\")\n",
    "    print(cms_train[-1])\n",
    "    print(classification_report(y_train,predicciones_train))\n",
    "\n",
    "    print(\"Test:\")\n",
    "    print(cms_test[-1])\n",
    "    print(classification_report(y_test,predicciones_test))\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(2,1,figsize=(10,5),tight_layout=True)\n",
    "fig.suptitle(\"     SVM\")\n",
    "\n",
    "ax[0].scatter(Cs,accuracy_train,s=50,alpha=0.8, label = 'Accuracy')\n",
    "ax[0].scatter(Cs,f1_train,s=50,alpha=0.8, label = 'F1-score')\n",
    "ax[0].scatter(Cs,recall_train,s=50,alpha=0.8, label = 'Recall')\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Training')\n",
    "ax[0].set_xticks(Cs)\n",
    "\n",
    "ax[1].scatter(Cs,accuracy_test,s=50,alpha=0.8, label = 'Accuracy')\n",
    "ax[1].scatter(Cs,f1_test,s=50,alpha=0.8, label = 'F1-score')\n",
    "ax[1].scatter(Cs,recall_test,s=50,alpha=0.5, label = 'Recall')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Test')\n",
    "ax[1].set_xlabel('C')\n",
    "ax[1].set_xticks(Cs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc5xBMayeAi3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7c. SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
