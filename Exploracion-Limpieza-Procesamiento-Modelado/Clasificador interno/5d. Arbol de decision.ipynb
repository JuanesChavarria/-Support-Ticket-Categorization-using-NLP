{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sX_k3xQPTtp8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report, recall_score, f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1638673084281,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "4Cr1_SwFTtqC",
    "outputId": "e011407b-b85a-4b9b-f4d8-ab95e7f4bba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%time datos = pd.read_csv('data_equilibrada.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1638673084281,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "cppPNsEObVqe",
    "outputId": "909e74e6-934b-4f94-874e-edd285badb6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1479, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2244,
     "status": "ok",
     "timestamp": 1638673086836,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "xBF1T_NtTtqD",
    "outputId": "06a1e494-9f8c-40a7-858b-ce50f285de32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "%time datos.tokens=datos.tokens.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XzPMzYueTtqE"
   },
   "outputs": [],
   "source": [
    "bow = pd.read_csv('bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1072,
     "status": "ok",
     "timestamp": 1638673090102,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "YSWgG2xdTtqE",
    "outputId": "814db34f-d129-43ed-d4eb-04fff7f3b7c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 68.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time tfidf=pd.DataFrame(TfidfVectorizer(vocabulary=bow.token.values).fit_transform(datos['tokens'].str.join(\" \")).toarray(), columns=bow.token.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1638673090331,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "iHNhVMcnTtqE",
    "outputId": "763d2b96-189f-4720-ab5d-7a5e97eb3a35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop</th>\n",
       "      <th>unsubscrib</th>\n",
       "      <th>verifi</th>\n",
       "      <th>inform</th>\n",
       "      <th>request</th>\n",
       "      <th>thank</th>\n",
       "      <th>address</th>\n",
       "      <th>lafargeholcim</th>\n",
       "      <th>benefit</th>\n",
       "      <th>com</th>\n",
       "      <th>...</th>\n",
       "      <th>chart</th>\n",
       "      <th>brotherhood</th>\n",
       "      <th>tanker</th>\n",
       "      <th>driver</th>\n",
       "      <th>vous</th>\n",
       "      <th>webmanag</th>\n",
       "      <th>theworknumb</th>\n",
       "      <th>ppay</th>\n",
       "      <th>tci</th>\n",
       "      <th>usf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070336</td>\n",
       "      <td>0.071192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099912</td>\n",
       "      <td>0.119191</td>\n",
       "      <td>0.114623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>0.084983</td>\n",
       "      <td>0.086018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.107704</td>\n",
       "      <td>0.109015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows × 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stop  unsubscrib    verifi    inform   request     thank   address  \\\n",
       "0     0.000000    0.000000  0.093465  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.062238   \n",
       "2     0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000    0.000000  0.000000  0.126601  0.000000  0.093610  0.000000   \n",
       "4     0.070336    0.071192  0.000000  0.000000  0.000000  0.084040  0.000000   \n",
       "...        ...         ...       ...       ...       ...       ...       ...   \n",
       "1474  0.084983    0.086018  0.000000  0.000000  0.000000  0.101541  0.000000   \n",
       "1475  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1476  0.019315    0.019551  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1477  0.107704    0.109015  0.000000  0.000000  0.000000  0.128688  0.000000   \n",
       "1478  0.000000    0.000000  0.300265  0.000000  0.371938  0.000000  0.128300   \n",
       "\n",
       "      lafargeholcim   benefit       com  ...  chart  brotherhood  tanker  \\\n",
       "0          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "1          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "2          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "3          0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "4          0.099912  0.119191  0.114623  ...    0.0          0.0     0.0   \n",
       "...             ...       ...       ...  ...    ...          ...     ...   \n",
       "1474       0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "1475       0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "1476       0.082313  0.000000  0.031478  ...    0.0          0.0     0.0   \n",
       "1477       0.000000  0.000000  0.175520  ...    0.0          0.0     0.0   \n",
       "1478       0.000000  0.000000  0.000000  ...    0.0          0.0     0.0   \n",
       "\n",
       "      driver      vous  webmanag  theworknumb  ppay  tci  usf  \n",
       "0        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "2        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "3        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "4        0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "...      ...       ...       ...          ...   ...  ...  ...  \n",
       "1474     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1475     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1476     0.0  0.447812       0.0          0.0   0.0  0.0  0.0  \n",
       "1477     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "1478     0.0  0.000000       0.0          0.0   0.0  0.0  0.0  \n",
       "\n",
       "[1479 rows x 708 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8hikogBcTtqF"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf.values, datos.etiquetas.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUekcNx_SoEC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11178,
     "status": "ok",
     "timestamp": 1638673901580,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "TfGTpxZ5TtqG",
    "outputId": "a8a23c07-d004-4139-f576-a4c205e7f226",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 10\n",
      "Train:\n",
      "[[ 42   0   0   1  35  65   6]\n",
      " [  2 101   0   0  84  44   0]\n",
      " [  0   0 143   1  37   0   0]\n",
      " [  0   0   0 129  17  27   0]\n",
      " [  0   0   0   0 125  34   1]\n",
      " [  0   0   0   0  16 131   0]\n",
      " [  6   0   0   0  17  43  76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.28      0.42       149\n",
      "           1       1.00      0.44      0.61       231\n",
      "           2       1.00      0.79      0.88       181\n",
      "           3       0.98      0.75      0.85       173\n",
      "           4       0.38      0.78      0.51       160\n",
      "           5       0.38      0.89      0.53       147\n",
      "           6       0.92      0.54      0.68       142\n",
      "\n",
      "    accuracy                           0.63      1183\n",
      "   macro avg       0.79      0.64      0.64      1183\n",
      "weighted avg       0.81      0.63      0.65      1183\n",
      "\n",
      "Test:\n",
      "[[ 9  1  0  0 11 15  1]\n",
      " [ 0 22  0  0 19 12  1]\n",
      " [ 0  0 35  0  6  0  0]\n",
      " [ 0  0  0 25  6  5  0]\n",
      " [ 0  0  0  0 33  4  2]\n",
      " [ 0  0  0  0  8 43  0]\n",
      " [ 2  0  0  0  2 18 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.24      0.38        37\n",
      "           1       0.96      0.41      0.57        54\n",
      "           2       1.00      0.85      0.92        41\n",
      "           3       1.00      0.69      0.82        36\n",
      "           4       0.39      0.85      0.53        39\n",
      "           5       0.44      0.84      0.58        51\n",
      "           6       0.80      0.42      0.55        38\n",
      "\n",
      "    accuracy                           0.62       296\n",
      "   macro avg       0.77      0.62      0.62       296\n",
      "weighted avg       0.77      0.62      0.62       296\n",
      "\n",
      "-----------\n",
      "max_depth: 20\n",
      "Train:\n",
      "[[120  20   0   0   0   4   5]\n",
      " [ 21 204   0   0   0   6   0]\n",
      " [  0  14 167   0   0   0   0]\n",
      " [  5   3   0 165   0   0   0]\n",
      " [ 20  14   0   0 124   2   0]\n",
      " [  5   2   0   0   0 140   0]\n",
      " [ 16  12   0   0   0   0 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.71       149\n",
      "           1       0.76      0.88      0.82       231\n",
      "           2       1.00      0.92      0.96       181\n",
      "           3       1.00      0.95      0.98       173\n",
      "           4       1.00      0.78      0.87       160\n",
      "           5       0.92      0.95      0.94       147\n",
      "           6       0.96      0.80      0.87       142\n",
      "\n",
      "    accuracy                           0.87      1183\n",
      "   macro avg       0.90      0.87      0.88      1183\n",
      "weighted avg       0.89      0.87      0.88      1183\n",
      "\n",
      "Test:\n",
      "[[20  6  1  1  2  5  2]\n",
      " [ 5 42  0  1  2  3  1]\n",
      " [ 0  6 35  0  0  0  0]\n",
      " [ 3  2  0 31  0  0  0]\n",
      " [ 3  1  0  1 32  0  2]\n",
      " [ 9  2  0  1  0 37  2]\n",
      " [ 6  2  0  0  0  3 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.54      0.48        37\n",
      "           1       0.69      0.78      0.73        54\n",
      "           2       0.97      0.85      0.91        41\n",
      "           3       0.89      0.86      0.87        36\n",
      "           4       0.89      0.82      0.85        39\n",
      "           5       0.77      0.73      0.75        51\n",
      "           6       0.79      0.71      0.75        38\n",
      "\n",
      "    accuracy                           0.76       296\n",
      "   macro avg       0.78      0.76      0.76       296\n",
      "weighted avg       0.77      0.76      0.76       296\n",
      "\n",
      "-----------\n",
      "max_depth: 30\n",
      "Train:\n",
      "[[136   0   7   0   0   0   6]\n",
      " [ 15 204  12   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  3   0   1 169   0   0   0]\n",
      " [ 13   0   4   0 142   0   1]\n",
      " [  1   0   0   0   0 146   0]\n",
      " [  7   0   1   0   0   0 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       149\n",
      "           1       1.00      0.88      0.94       231\n",
      "           2       0.88      1.00      0.94       181\n",
      "           3       1.00      0.98      0.99       173\n",
      "           4       1.00      0.89      0.94       160\n",
      "           5       1.00      0.99      1.00       147\n",
      "           6       0.95      0.94      0.95       142\n",
      "\n",
      "    accuracy                           0.94      1183\n",
      "   macro avg       0.94      0.94      0.94      1183\n",
      "weighted avg       0.95      0.94      0.94      1183\n",
      "\n",
      "Test:\n",
      "[[24  1  4  1  2  2  3]\n",
      " [ 4 38  3  3  3  2  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 2  2  1 30  0  0  1]\n",
      " [ 1  0  0  1 34  0  3]\n",
      " [ 6  0  2  1  0 37  5]\n",
      " [ 4  0  0  0  0  3 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62        37\n",
      "           1       0.93      0.70      0.80        54\n",
      "           2       0.80      1.00      0.89        41\n",
      "           3       0.83      0.83      0.83        36\n",
      "           4       0.87      0.87      0.87        39\n",
      "           5       0.84      0.73      0.78        51\n",
      "           6       0.70      0.82      0.76        38\n",
      "\n",
      "    accuracy                           0.79       296\n",
      "   macro avg       0.80      0.80      0.79       296\n",
      "weighted avg       0.81      0.79      0.79       296\n",
      "\n",
      "-----------\n",
      "max_depth: 40\n",
      "Train:\n",
      "[[144   0   0   0   0   0   5]\n",
      " [  9 220   2   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  7   0   0   0 152   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  3   0   0   0   0   0 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       149\n",
      "           1       1.00      0.95      0.98       231\n",
      "           2       0.99      1.00      0.99       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       1.00      0.95      0.97       160\n",
      "           5       1.00      1.00      1.00       147\n",
      "           6       0.96      0.98      0.97       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.98      0.98      0.98      1183\n",
      "weighted avg       0.98      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[26  1  1  2  2  2  3]\n",
      " [ 8 40  0  0  3  2  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  2  1 32  0  0  1]\n",
      " [ 1  0  0  1 34  1  2]\n",
      " [ 3  3  0  1  0 40  4]\n",
      " [ 2  0  0  0  0  3 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68        37\n",
      "           1       0.87      0.74      0.80        54\n",
      "           2       0.95      1.00      0.98        41\n",
      "           3       0.89      0.89      0.89        36\n",
      "           4       0.87      0.87      0.87        39\n",
      "           5       0.83      0.78      0.81        51\n",
      "           6       0.75      0.87      0.80        38\n",
      "\n",
      "    accuracy                           0.83       296\n",
      "   macro avg       0.83      0.84      0.83       296\n",
      "weighted avg       0.83      0.83      0.83       296\n",
      "\n",
      "-----------\n",
      "max_depth: 50\n",
      "Train:\n",
      "[[144   0   0   0   0   0   5]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  7   0   0   0 152   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  3   0   0   0   0   0 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       1.00      0.95      0.97       160\n",
      "           5       1.00      1.00      1.00       147\n",
      "           6       0.96      0.98      0.97       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.98      0.98      0.98      1183\n",
      "weighted avg       0.99      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[23  2  2  2  2  3  3]\n",
      " [ 4 41  1  2  2  3  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  3  1 32  0  0  0]\n",
      " [ 2  0  0  1 34  0  2]\n",
      " [ 3  1  1  2  0 40  4]\n",
      " [ 2  0  0  0  0  3 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65        37\n",
      "           1       0.87      0.76      0.81        54\n",
      "           2       0.89      1.00      0.94        41\n",
      "           3       0.82      0.89      0.85        36\n",
      "           4       0.89      0.87      0.88        39\n",
      "           5       0.82      0.78      0.80        51\n",
      "           6       0.77      0.87      0.81        38\n",
      "\n",
      "    accuracy                           0.82       296\n",
      "   macro avg       0.82      0.83      0.82       296\n",
      "weighted avg       0.82      0.82      0.82       296\n",
      "\n",
      "-----------\n",
      "max_depth: 60\n",
      "Train:\n",
      "[[144   0   0   0   0   0   5]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  7   0   0   0 152   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  3   0   0   0   0   0 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       1.00      0.95      0.97       160\n",
      "           5       1.00      1.00      1.00       147\n",
      "           6       0.96      0.98      0.97       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.98      0.98      0.98      1183\n",
      "weighted avg       0.99      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[23  2  2  3  2  2  3]\n",
      " [ 4 40  1  2  3  2  2]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  1  1 33  0  0  1]\n",
      " [ 1  0  0  1 34  1  2]\n",
      " [ 4  1  0  1  2 39  4]\n",
      " [ 2  0  0  0  0  3 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65        37\n",
      "           1       0.91      0.74      0.82        54\n",
      "           2       0.91      1.00      0.95        41\n",
      "           3       0.82      0.92      0.87        36\n",
      "           4       0.83      0.87      0.85        39\n",
      "           5       0.83      0.76      0.80        51\n",
      "           6       0.73      0.87      0.80        38\n",
      "\n",
      "    accuracy                           0.82       296\n",
      "   macro avg       0.82      0.83      0.82       296\n",
      "weighted avg       0.82      0.82      0.82       296\n",
      "\n",
      "-----------\n",
      "max_depth: 70\n",
      "Train:\n",
      "[[144   0   0   0   0   0   5]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  7   0   0   0 152   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  3   0   0   0   0   0 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       1.00      0.95      0.97       160\n",
      "           5       1.00      1.00      1.00       147\n",
      "           6       0.96      0.98      0.97       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.98      0.98      0.98      1183\n",
      "weighted avg       0.99      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[24  3  2  1  2  2  3]\n",
      " [ 4 41  1  1  2  3  2]\n",
      " [ 0  1 40  0  0  0  0]\n",
      " [ 0  1  0 34  0  0  1]\n",
      " [ 2  0  0  1 34  0  2]\n",
      " [ 2  0  2  3  0 40  4]\n",
      " [ 2  0  0  0  0  3 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68        37\n",
      "           1       0.89      0.76      0.82        54\n",
      "           2       0.89      0.98      0.93        41\n",
      "           3       0.85      0.94      0.89        36\n",
      "           4       0.89      0.87      0.88        39\n",
      "           5       0.83      0.78      0.81        51\n",
      "           6       0.73      0.87      0.80        38\n",
      "\n",
      "    accuracy                           0.83       296\n",
      "   macro avg       0.83      0.84      0.83       296\n",
      "weighted avg       0.83      0.83      0.83       296\n",
      "\n",
      "-----------\n",
      "max_depth: 80\n",
      "Train:\n",
      "[[144   0   0   0   0   0   5]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  7   0   0   0 152   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  3   0   0   0   0   0 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       1.00      0.95      0.97       160\n",
      "           5       1.00      1.00      1.00       147\n",
      "           6       0.96      0.98      0.97       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.98      0.98      0.98      1183\n",
      "weighted avg       0.99      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[24  3  2  1  2  2  3]\n",
      " [ 4 40  2  3  2  1  2]\n",
      " [ 0  1 40  0  0  0  0]\n",
      " [ 0  1  1 33  0  0  1]\n",
      " [ 2  0  0  1 34  0  2]\n",
      " [ 3  0  1  1  1 41  4]\n",
      " [ 2  0  0  0  0  3 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67        37\n",
      "           1       0.89      0.74      0.81        54\n",
      "           2       0.87      0.98      0.92        41\n",
      "           3       0.85      0.92      0.88        36\n",
      "           4       0.87      0.87      0.87        39\n",
      "           5       0.87      0.80      0.84        51\n",
      "           6       0.73      0.87      0.80        38\n",
      "\n",
      "    accuracy                           0.83       296\n",
      "   macro avg       0.82      0.83      0.83       296\n",
      "weighted avg       0.83      0.83      0.83       296\n",
      "\n",
      "-----------\n",
      "max_depth: 90\n",
      "Train:\n",
      "[[144   0   0   0   0   0   5]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  7   0   0   0 152   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  3   0   0   0   0   0 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       1.00      0.95      0.97       160\n",
      "           5       1.00      1.00      1.00       147\n",
      "           6       0.96      0.98      0.97       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.98      0.98      0.98      1183\n",
      "weighted avg       0.99      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[25  2  1  2  2  3  2]\n",
      " [ 3 45  0  1  3  1  1]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  1  1 33  0  0  1]\n",
      " [ 1  0  0  2 34  0  2]\n",
      " [ 2  1  0  2  1 41  4]\n",
      " [ 2  0  0  0  0  3 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.71        37\n",
      "           1       0.92      0.83      0.87        54\n",
      "           2       0.95      1.00      0.98        41\n",
      "           3       0.82      0.92      0.87        36\n",
      "           4       0.85      0.87      0.86        39\n",
      "           5       0.85      0.80      0.83        51\n",
      "           6       0.77      0.87      0.81        38\n",
      "\n",
      "    accuracy                           0.85       296\n",
      "   macro avg       0.85      0.85      0.85       296\n",
      "weighted avg       0.85      0.85      0.85       296\n",
      "\n",
      "-----------\n",
      "max_depth: 100\n",
      "Train:\n",
      "[[144   0   0   0   0   0   5]\n",
      " [  2 229   0   0   0   0   0]\n",
      " [  0   0 181   0   0   0   0]\n",
      " [  0   0   0 173   0   0   0]\n",
      " [  7   0   0   0 152   0   1]\n",
      " [  0   0   0   0   0 147   0]\n",
      " [  3   0   0   0   0   0 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       149\n",
      "           1       1.00      0.99      1.00       231\n",
      "           2       1.00      1.00      1.00       181\n",
      "           3       1.00      1.00      1.00       173\n",
      "           4       1.00      0.95      0.97       160\n",
      "           5       1.00      1.00      1.00       147\n",
      "           6       0.96      0.98      0.97       142\n",
      "\n",
      "    accuracy                           0.98      1183\n",
      "   macro avg       0.98      0.98      0.98      1183\n",
      "weighted avg       0.99      0.98      0.98      1183\n",
      "\n",
      "Test:\n",
      "[[24  2  2  2  2  2  3]\n",
      " [ 2 42  1  2  2  3  2]\n",
      " [ 0  0 41  0  0  0  0]\n",
      " [ 0  1  1 33  0  0  1]\n",
      " [ 1  1  0  1 34  0  2]\n",
      " [ 3  2  1  1  0 40  4]\n",
      " [ 2  0  0  0  0  3 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70        37\n",
      "           1       0.88      0.78      0.82        54\n",
      "           2       0.89      1.00      0.94        41\n",
      "           3       0.85      0.92      0.88        36\n",
      "           4       0.89      0.87      0.88        39\n",
      "           5       0.83      0.78      0.81        51\n",
      "           6       0.73      0.87      0.80        38\n",
      "\n",
      "    accuracy                           0.83       296\n",
      "   macro avg       0.83      0.84      0.83       296\n",
      "weighted avg       0.84      0.83      0.83       296\n",
      "\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "cms_train=[]\n",
    "cms_test=[]\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "reporte_train = []\n",
    "reporte_test = []\n",
    "max_depths = np.arange(10,110,10)\n",
    "for max_depth in max_depths:\n",
    "    print(\"max_depth:\",max_depth)\n",
    "    knn = DecisionTreeClassifier(max_depth=max_depth,class_weight='balanced')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    predicciones_train=knn.predict(X_train)\n",
    "    predicciones_test=knn.predict(X_test)\n",
    "\n",
    "    cms_train.append(confusion_matrix(y_train,predicciones_train))\n",
    "    cms_test.append(confusion_matrix(y_test,predicciones_test))\n",
    "    accuracy_train.append(accuracy_score(y_train,predicciones_train))\n",
    "    accuracy_test.append(accuracy_score(y_test,predicciones_test))\n",
    "    f1_train.append(f1_score(y_train,predicciones_train,average='weighted'))\n",
    "    f1_test.append(f1_score(y_test,predicciones_test,average='weighted'))\n",
    "    recall_train.append(recall_score(y_train,predicciones_train,average='weighted'))\n",
    "    recall_test.append(recall_score(y_test,predicciones_test,average='weighted'))\n",
    "    reporte_train.append(precision_recall_fscore_support(y_train,predicciones_train))\n",
    "    reporte_test.append(precision_recall_fscore_support(y_test,predicciones_test))\n",
    "    \n",
    "    print(\"Train:\")\n",
    "    print(cms_train[-1])\n",
    "    print(classification_report(y_train,predicciones_train))\n",
    "\n",
    "    print(\"Test:\")\n",
    "    print(cms_test[-1])\n",
    "    print(classification_report(y_test,predicciones_test))\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1638673902391,
     "user": {
      "displayName": "Santiago Méndez Mejía",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoJ0JO0MwgPRPYCsD-gRWO6KWp1gwlr42D49DHTA=s64",
      "userId": "17320620680853051936"
     },
     "user_tz": 300
    },
    "id": "T3LnTYJkXOoz",
    "outputId": "1136bd58-7ed3-4a49-9815-ba185dfc96a0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(2,1,figsize=(10,6),tight_layout=True)\n",
    "fig.suptitle(\"     DecisionTree\")\n",
    "ax[0].scatter(max_depths,accuracy_train,s=50,alpha=0.8, label = 'Accuracy')\n",
    "ax[0].scatter(max_depths,f1_train,s=50,alpha=0.8, label = 'F1-score')\n",
    "ax[0].scatter(max_depths,recall_train,s=50,alpha=0.8, label = 'Recall')\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Training')\n",
    "# ax[0].set_xlabel('max_depth')\n",
    "\n",
    "ax[1].scatter(max_depths,accuracy_test,s=50,alpha=0.8, label = 'Accuracy')\n",
    "ax[1].scatter(max_depths,f1_test,s=50,alpha=0.8, label = 'F1-score')\n",
    "ax[1].scatter(max_depths,recall_test,s=50,alpha=0.8, label = 'Recall')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Test')\n",
    "ax[1].set_xlabel('max_depth')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihhQb2dHfYUX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7d. Arbol de decision.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
